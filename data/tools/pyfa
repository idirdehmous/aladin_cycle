#! /usr/bin/env python3
# basic FA utilities combined in 1 call
# Alex Deckmyn, KMI, 2023
# --date --size --ls --prod --header  --hum # --subset --frame
import sys
import struct
import os
#import argparse
#import math
import datetime
import re

def help () :
  print("pyfa <task> <filename>")
  print("    <task> = ls | date | size | prod | header | humi")

def get_header(fafile) :
  # read the first sector : 22 big-endian long integers
  # the end of this sector may also contain the locations of
  # additional index sectors
  fafile.seek(0)
  header22 = list(struct.unpack(">22Q", fafile.read(22*8)))
  header = { 
          'sector_size'   : header22[0] , # sector size given in 8 byte words
          'name_length'   : header22[1] , # should always be 16
          'closure'       : header22[2] , # should be 0
          'header_len'    : header22[3] , # should be 22
          'nsectors'      : header22[4] , # >=4
          'nrecords'      : header22[5] , # total nr of records in index (some may be empty)
          'minlen'        : header22[6] , # shortest data record (1 for FA files)
          'maxlen'        : header22[7] , # longest data record
          'datalen'       : header22[8] , # total length of data records
          'nrewr_same'    : header22[9] , # rewrites same length
          'nrewr_shorter' : header22[10] , # rewrites shorter (small data hole)
          'nrewr_longer'  : header22[11] , # rewrites longer (-> leaves hole in index)
          'n_rec_seq'     : header22[12] , # records per index sequence=sector_size/2
          'creation_date' : header22[13] ,
          'creation_time' : header22[14] ,
          'last_mod_date' : header22[15] ,
          'last_mod_time' : header22[16] ,
          'first_mod_date': header22[17] ,
          'first_mod_time': header22[18] ,
          'n_index'       : header22[19] , # nr of index sectors, ==1 even if there are more???
          'nholes'        : header22[20] , # nr of "holes" in the index
          'max_sectors'   : header22[21]   # nr data sectors used
          }
  # NOTE: maybe n_index > 1 means you have 2 consecutive index sectors, 
  #       so doubling n_req_seq
  #       but I have never encountered such a file...
  if header['name_length'] != 16 or header['header_len'] != 22 :
    print('ERROR: not a regular FA file.')
    exit(1)
  # now we build a list of index sectors
  # first index starts in 2nd sector
  if header['nrecords'] <= header['n_rec_seq'] :
    header['index_list'] = [ [ 1, header['nrecords'] ] ]
  else :
    # multiple name & address sectors
    n_index = header['nrecords'] // header['n_rec_seq']
    fafile.seek( 8*(header['sector_size'] - n_index) )
    indlist = list(struct.unpack(">%iQ"%n_index,fafile.read(n_index*8)))
    # records per index list: only last one may have < n_rec_seq
    ilist =[2] + list(reversed(indlist))
    llist = [ header['n_rec_seq'] for i in range(n_index) ]
    llist.append(header['nrecords'] % header['n_rec_seq'])
    header['index_list'] = [[ ilist[i]-1,llist[i] ] for i in range(n_index+1)  ]
  return(header)

def get_fieldnames(fafile, header) :
  fieldnames = []
  nind = len(header['index_list'])
  for i in range(nind) :
    ind = header['index_list'][i]
    fafile.seek(ind[0] * 8 * header['sector_size'])
    fieldnames = fieldnames + [ x.decode('ascii') for x in 
        list(struct.unpack("16s"*ind[1], fafile.read(16*ind[1]))) ]
  return(fieldnames)

def get_locations(fafile, header) :
  nind = len(header['index_list'])
  data_loc = []
  data_len = []
  for i in range(nind) :
    ind = header['index_list'][i]
    # FIXME: maybe +1 should rather be +header['n_index'] ???
    fafile.seek( (ind[0] + 1) * 8 * header['sector_size'])
    sec3 = struct.unpack(">%iQ"%(2*ind[1]), fafile.read(16*ind[1]) )
    # shift location by one for correct result with seek ()
    # and multiply by 8 for bytes in stead of words
    data_loc = data_loc + [ (x-1)*8 for x in sec3[1::2] ]
    data_len = data_len + [ x*8 for x in sec3[::2] ]
  return(data_loc, data_len)

def get_list(fafile, header) :
  fieldnames = get_fieldnames(fafile, header)
  dloc, dlen = get_locations(fafile, header)
  hole_indices = [i for i in range(header['nrecords']) if fieldnames[i]==' '*16]
  if len(hole_indices) != header['nholes'] :
      print("ERROR: inconsistent holes in index sector.")
  # NOTE: in python < 3.7, a dictionary may not remain in right order...
  flist = { fieldnames[i]:[ dloc[i], dlen[i] ]
      for i in range(header['nrecords'])
      if i not in hole_indices }
  hlist = { 'h'+str(i+1):[dloc[i],dlen[i]] for i in hole_indices }
  return flist, hlist

def list_fields(fafile, header) :
  # from file header: section size in 8-byte words
  flist, hlist = get_list(fafile, header)
  ncol = 3
  fn = list(flist.keys())
  for i in range(0, header['nrecords'] - header['nholes'], ncol) :
      print( f"{i+1:4d} : " + "  ".join(fn[i:(i+ncol)]) )

def read_data_field(fafile, dloc) :
  # dloc contains data location and length min bytes
  # return raw bytes
  fafile.seek(dloc[0])
  return(fafile.read(dloc[1]))

def get_datetime(fafile, header) :
  flist, hlist = get_list(fafile, header)
  df1 = struct.unpack(">11Q", read_data_field(fafile, flist['DATE-DES-DONNEES']))
  # fcdate = datetime.datetime(df1[0], df1[1], df1[2], df1[3], df1[4], 0)
  fcdate = datetime.datetime(df1[0], df1[1], df1[2], 0, 0, 0)
  if 'DATX-DES-DONNEES' in flist.keys() :
    # time of day given in seconds
    df2 = struct.unpack(">11Q", read_data_field(fafile, flist['DATX-DES-DONNEES']))
    fcdate = fcdate + datetime.timedelta(seconds = df2[2])
#    print(df1)
#    print(df2)
  else :
    # time of day given in  hh:mm
    df2 = None
    fcdate = fcdate + datetime.timedelta(hours=df1[3], minutes=df1[4])

  # lead time is usually in hours, but not always!
  if df1[5] == 0 : # minutes
    lt = " + %i minutes" % df1[6]
  elif df1[5] == 1 : # hours
    lt = " + %i hours" % df1[6]
  elif df1[5] == 254 : # seconds
    lt = " + %i seconds" % df1[6]
#    lt = str(df2[3]).zfill(2)+" seconds"

#  if not df2 is None :
      # fields 4-5 are P1-P2 in seconds (for time intervals)
#      ss = df2[2] # start of fc: time of day in seconds
#      lt_ss = df2[3] # lead time in seconds
#      tstep = df2[6] # time step in seconds
#  print("{0}-{1}-{2}T{3}:{4}Z + {5}".format(yyyy, mm, dd, rr, MM, lt))
  print(fcdate.strftime("%Y-%m-%dT%H:%MZ") + lt)


def find_in_list(flist, templates) :
  # return a list (with byte location) of all fields matching a list of templates
  # read templates from a file (containing a python command templates = [...])
  # exec(open(template_file).read())
  matching = { k:v for k,v in flist.items() if any ( re.search(ttt, k) for ttt in templates ) }
  # template may be e.g. [ "^S[0-9]{3}TEMPERATURE", "^SURFPREC" ]
  return(matching)

def check_type(fafile, field="S001HUMI.SPECIFI") :
  flist, hlist = get_list(fafile, header)
  fafile.seek(flist[field][0])
  ftype = struct.unpack(">%iQ"%(2), fafile.read(16) )
  # second integer = 0 means GP, !=0 means SPEC
  if ftype[1] == 0 :
    return("gp")
  else :
    return("sp")


ftask = sys.argv[1]
fname = sys.argv[2]

fafile = open(fname, "rb")
header = get_header(fafile)

if ftask == 'header' :
  print(header)
elif ftask == 'prod' :
    print(f"Creation: {header['creation_date']:8i} : {header['creation_time']:6i}")
    print(f"Last mod: {header['last_mod_date']:8i} : {header['last_mod_time']:6i}")
elif ftask == 'ls' :
  list_fields(fafile, header)
elif ftask == 'size' :
  expected_size = 8 * header['sector_size'] * header['nsectors']
  real_size = os.stat(fname).st_size
  print(f"expected size : {expected_size}")
  print(f"actual size   : {real_size}")
  if expected_size != real_size :
    print("ERROR in file size")
    exit(1)
elif ftask == 'date' :
  get_datetime(fafile, header)
elif ftask == 'humi' :
  print(check_type(fafile, 'S001HUMI.SPECIFI'))
else :
  help()



